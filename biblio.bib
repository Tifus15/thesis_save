%% This is file `DEMO-TUDaBibliography.bib' version 3.32 (2023/06/19),
%% it is part of
%% TUDa-CI -- Corporate Design for TU Darmstadt
%% ----------------------------------------------------------------------------
%%
%%  Copyright (C) 2018--2023 by Marei Peischl <marei@peitex.de>
%%
%% ============================================================================
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3c
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%% http://www.latex-project.org/lppl.txt
%% and version 1.3c or later is part of all distributions of LaTeX
%% version 2008/05/04 or later.
%%
%% This work has the LPPL maintenance status `maintained'.
%%
%% The Current Maintainers of this work are
%%   Marei Peischl <tuda-ci@peitex.de>
%%   Markus Lazanowski <latex@ce.tu-darmstadt.de>
%%
%% The development respository can be found at
%% https://github.com/tudace/tuda_latex_templates
%% Please use the issue tracker for feedback!
%%
%% If you need a compiled version of this document, have a look at
%% http://mirror.ctan.org/macros/latex/contrib/tuda-ci/doc
%% or at the documentation directory of this package (if installed)
%% <path to your LaTeX distribution>/doc/latex/tuda-ci
%% ============================================================================
%%
% !TeX program = lualatex
%%

%Beispiel BibTeX-Datenbank für die Verwendung von biblatex und biber



@misc{neuralODE,
title={Neural Ordinary Differential Equations}, 
author={Ricky T. Q. Chen and Yulia Rubanova and Jesse Bettencourt and David Duvenaud},
year={2019},
eprint={1806.07366},
archivePrefix={arXiv},
primaryClass={cs.LG},
url={https://arxiv.org/abs/1806.07366}
}

@misc{Delan,
	title={Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning}, 
	author={Michael Lutter and Christian Ritter and Jan Peters},
	year={2019},
	eprint={1907.04490},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1907.04490}, 
}


@book{ClassPhy,
	author = { Matthew J. Benacquista , Joseph D. Romano},
	title = {Classical Mechanics },
	date = {2018},
	ISBN = {978-3-319-68779-7},


}
@inbook{osci, title={Harmonic Oscillator}, booktitle={Fundamentals of Mechanics}, publisher={Foundation Books}, author={Chandra, Suresh and Sharma, Mohit Kumar and Sharma, Monika}, year={2014}, pages={150–174}}

@inproceedings{dalam,
	title={Holonomic versus nonholonomic constraints},
	author={Mattias Flygare},
	year={2012},
	url={https://api.semanticscholar.org/CorpusID:118677177}
}
@misc{ortho,
	title={Virtual Displacement in Lagrangian Dynamics}, 
	author={Subhankar Ray and J. Shamanna},
	year={2004},
	eprint={physics/0410123},
	archivePrefix={arXiv},
	primaryClass={physics.ed-ph},
	url={https://arxiv.org/abs/physics/0410123}, 
}
@inproceedings{ham,
	author = "Montague, B. W.",
	title = "{Basic Hamiltonian mechanics}",
	booktitle = "{CERN Accelerator School: Course on Advanced Accelerator Physics (CAS)}",
	pages = "1--14",
	year = "1993"}


@inbook{mlprnn, place={Cambridge}, title={Foundations of Deep Learning}, booktitle={Deep Learning on Graphs}, publisher={Cambridge University Press}, author={Ma, Yao and Tang, Jiliang}, year={2021}, pages={43–72}} 
@article{acts,
	title={Activation functions in deep learning: A comprehensive survey and benchmark},
	author={Shiv Ram Dubey and Satish Kumar Singh and Bidyut Baran Chaudhuri},
	journal={Neurocomputing},
	year={2021},
	volume={503},
	pages={92-108},
	url={https://api.semanticscholar.org/CorpusID:250089226}
}

@misc{rnn,
	title={Recurrent Neural Networks (RNNs): A gentle Introduction and Overview}, 
	author={Robin M. Schmidt},
	year={2019},
	eprint={1912.05911},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1912.05911}, 
}
@Inbook{rnntypes,
	author="Das, Susmita
	and Tariq, Amara
	and Santos, Thiago
	and Kantareddy, Sai Sandeep
	and Banerjee, Imon",
	editor="Colliot, Olivier",
	title="Recurrent Neural Networks (RNNs): Architectures, Training Tricks, and Introduction to Influential Research",
	bookTitle="Machine Learning for Brain Disorders",
	year="2023",
	publisher="Springer US",
	address="New York, NY",
	pages="117--138",
	abstract="Recurrent neural networks (RNNs) are neural network architectures with hidden state and which use feedback loops to process a sequence of data that ultimately informs the final output. Therefore, RNN models can recognize sequential characteristics in the data and help to predict the next likely data point in the data sequence. Leveraging the power of sequential data processing, RNN use cases tend to be connected to either language models or time-series data analysis. However, multiple popular RNN architectures have been introduced in the field, starting from SimpleRNN and LSTM to deep RNN, and applied in different experimental settings. In this chapter, we will present six distinct RNN architectures and will highlight the pros and cons of each model. Afterward, we will discuss real-life tips and tricks for training the RNN models. Finally, we will present four popular language modeling applications of the RNN models --text classification, summarization, machine translation, and image-to-text translation-- thereby demonstrating influential research in the field.",
	isbn="978-1-0716-3195-9",
	doi="10.1007/978-1-0716-3195-9_4",
	url="https://doi.org/10.1007/978-1-0716-3195-9_4"
}
@article{gru,
	title={Gate-variants of Gated Recurrent Unit (GRU) neural networks},
	author={Rahul Dey and Fathi M. Salem},
	journal={2017 IEEE 60th International Midwest Symposium on Circuits and Systems (MWSCAS)},
	year={2017},
	pages={1597-1600},
	url={https://api.semanticscholar.org/CorpusID:8492900}
}
@misc{hnn,
	title={Hamiltonian Neural Networks}, 
	author={Sam Greydanus and Misko Dzamba and Jason Yosinski},
	year={2019},
	eprint={1906.01563},
	archivePrefix={arXiv},
	primaryClass={cs.NE},
	url={https://arxiv.org/abs/1906.01563}, 
}
@article{papthreebody,
	title={Three Classes of Newtonian Three-Body Planar Periodic Orbits},
	volume={110},
	ISSN={1079-7114},
	url={http://dx.doi.org/10.1103/PhysRevLett.110.114301},
	DOI={10.1103/physrevlett.110.114301},
	number={11},
	journal={Physical Review Letters},
	publisher={American Physical Society (APS)},
	author={Šuvakov, Milovan and Dmitrašinović, V.},
	year={2013},
	month=mar }

@online{web,
	author = {Institute of Physics Belgrade},
	title = {THREE-BODY GALLERY},
	url = {http://three-body.ipb.ac.rs/},
}
@article{hudomal2015new,
	title={New periodic solutions to the three-body problem and gravitational waves},
	author={Hudomal, Ana},
	journal={Master of Science Thesis at the Faculty of Physics, Belgrade University},
	year={2015}
}


@article{mlppic,
	title = {Deep neural networks in the cloud: Review, applications, challenges and research directions},
	journal = {Neurocomputing},
	volume = {545},
	pages = {126327},
	year = {2023},
	issn = {0925-2312},
	doi = {https://doi.org/10.1016/j.neucom.2023.126327},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231223004502},
	author = {Kit Yan Chan and Bilal Abu-Salih and Raneem Qaddoura and Ala’ M. Al-Zoubi and Vasile Palade and Duc-Son Pham and Javier Del Ser and Khan Muhammad},
	keywords = {Big data, Cloud computing, Deep neural networks, High-performance computing}
	
}

@inproceedings{rnn_picture,
	author = {Feng, Weijiang and Guan, Naiyang and Li, Yuan and Zhang, Xiang and Luo, Zhigang},
	year = {2017},
	month = {05},
	pages = {681-688},
	title = {Audio visual speech recognition with multimodal recurrent neural networks},
	doi = {10.1109/IJCNN.2017.7965918}
}

@article{gru_picture,
	author = {Mohsen, Saeed},
	year = {2023},
	month = {05},
	pages = {},
	title = {Recognition of human activity using GRU deep learning algorithm},
	volume = {82},
	journal = {Multimedia Tools and Applications},
	doi = {10.1007/s11042-023-15571-y}
}

@misc{adamW,
	title={Decoupled Weight Decay Regularization}, 
	author={Ilya Loshchilov and Frank Hutter},
	year={2019},
	eprint={1711.05101},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1711.05101}, 
}
@article{dopri5,
	title = {A fifth-order interpolant for the Dormand and Prince Runge-Kutta method},
	journal = {Journal of Computational and Applied Mathematics},
	volume = {29},
	number = {1},
	pages = {91-100},
	year = {1990},
	issn = {0377-0427},
	doi = {https://doi.org/10.1016/0377-0427(90)90198-9},
	url = {https://www.sciencedirect.com/science/article/pii/0377042790901989},
	author = {M. Calvo and J.I. Montijano and L. Randez},
	keywords = {Ordinary differential equations, Runge-Kutta methods, interpolation},
	abstract = {A family of fifth-order interpolants for the fifth-order solution provided by the Dormand and Prince Runge-Kutta pair RK5(4)7M which requires two additional function evaluations per step is presented. An optimal interpolant in this family has been determined by choosing the parameters to minimize the leading coefficients of the local truncation error of the continuous solution. Some numerical experiments with the nonstiff DETEST problems show that the proposed optimal method has a good interpolatory behavior.}
}

