%% This is file `DEMO-TUDaBibliography.bib' version 3.32 (2023/06/19),
%% it is part of
%% TUDa-CI -- Corporate Design for TU Darmstadt
%% ----------------------------------------------------------------------------
%%
%%  Copyright (C) 2018--2023 by Marei Peischl <marei@peitex.de>
%%
%% ============================================================================
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3c
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%% http://www.latex-project.org/lppl.txt
%% and version 1.3c or later is part of all distributions of LaTeX
%% version 2008/05/04 or later.
%%
%% This work has the LPPL maintenance status `maintained'.
%%
%% The Current Maintainers of this work are
%%   Marei Peischl <tuda-ci@peitex.de>
%%   Markus Lazanowski <latex@ce.tu-darmstadt.de>
%%
%% The development respository can be found at
%% https://github.com/tudace/tuda_latex_templates
%% Please use the issue tracker for feedback!
%%
%% If you need a compiled version of this document, have a look at
%% http://mirror.ctan.org/macros/latex/contrib/tuda-ci/doc
%% or at the documentation directory of this package (if installed)
%% <path to your LaTeX distribution>/doc/latex/tuda-ci
%% ============================================================================
%%
% !TeX program = lualatex
%%
@misc{wave,
	title={Graph WaveNet for Deep Spatial-Temporal Graph Modeling}, 
	author={Zonghan Wu and Shirui Pan and Guodong Long and Jing Jiang and Chengqi Zhang},
	year={2019},
	eprint={1906.00121},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1906.00121}, 
}
@article{dgl,
	author = "Wang, Minjie and others",
	title = "{Deep Graph Library: A Graph-Centric, Highly-Performant Package for Graph Neural Networks}",
	eprint = "1909.01315",
	archivePrefix = "arXiv",
	primaryClass = "cs.LG",
	month = "9",
	year = "2019"
}
@misc{kan,
	title={KAN: Kolmogorov-Arnold Networks}, 
	author={Ziming Liu and Yixuan Wang and Sachin Vaidya and Fabian Ruehle and James Halverson and Marin Soljačić and Thomas Y. Hou and Max Tegmark},
	year={2024},
	eprint={2404.19756},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2404.19756}, 
}
@INPROCEEDINGS{gnngru,
	
	author={Donnangelo, F. and Bianchi, I. and Rodríguez, A. and Castro, A.},
	
	booktitle={2023 23rd International Conference on Transparent Optical Networks (ICTON)}, 
	
	title={Predicting loss in optical transport segments: A GNN-GRU approach for a nationwide optical network}, 
	
	year={2023},
	
	volume={},
	
	number={},
	
	pages={1-4},
	
	keywords={Optical losses;Integrated optics;Web and internet services;Predictive models;Optical network units;Graph neural networks;Spatial databases;Loss prediction;Deep Learning;Graph Neural Networks;Gated Recurrent Units},
	
	doi={10.1109/ICTON59386.2023.10207281}}


@misc{GGSNN,
	title={Gated Graph Sequence Neural Networks}, 
	author={Yujia Li and Daniel Tarlow and Marc Brockschmidt and Richard Zemel},
	year={2017},
	eprint={1511.05493},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1511.05493}, 
}
@misc{GNNODE,
	title={Hamiltonian Graph Networks with ODE Integrators}, 
	author={Alvaro Sanchez-Gonzalez and Victor Bapst and Kyle Cranmer and Peter Battaglia},
	year={2019},
	eprint={1909.12790},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1909.12790}, 
}
@article{att,
	author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
	title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
	journal = {Journal of Machine Learning Research},
	year    = {2014},
	volume  = {15},
	number  = {56},
	pages   = {1929--1958},
	url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}
@misc{gat,
	title={Graph Attention Networks}, 
	author={Petar Veličković and Guillem Cucurull and Arantxa Casanova and Adriana Romero and Pietro Liò and Yoshua Bengio},
	year={2018},
	eprint={1710.10903},
	archivePrefix={arXiv},
	primaryClass={stat.ML},
	url={https://arxiv.org/abs/1710.10903}, 
}
@misc{cheb,
	title={Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering}, 
	author={Michaël Defferrard and Xavier Bresson and Pierre Vandergheynst},
	year={2017},
	eprint={1606.09375},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1606.09375}, 
}
@misc{gcn,
	title={Semi-Supervised Classification with Graph Convolutional Networks}, 
	author={Thomas N. Kipf and Max Welling},
	year={2017},
	eprint={1609.02907},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1609.02907}, 
}
@misc{cheb,
	title={Wavelets on Graphs via Spectral Graph Theory}, 
	author={David K Hammond and Pierre Vandergheynst and Rémi Gribonval},
	year={2009},
	eprint={0912.3848},
	archivePrefix={arXiv},
	primaryClass={math.FA},
	url={https://arxiv.org/abs/0912.3848}, 
}
@misc{sgn,
	title={Spectral Networks and Locally Connected Networks on Graphs}, 
	author={Joan Bruna and Wojciech Zaremba and Arthur Szlam and Yann LeCun},
	year={2014},
	eprint={1312.6203},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1312.6203}, 
}
%Beispiel BibTeX-Datenbank für die Verwendung von biblatex und biber
@misc{torchdiffeq,
	author={Chen, Ricky T. Q.},
	title={torchdiffeq},
	year={2018},
	url={https://github.com/rtqichen/torchdiffeq},
}
@misc{nb,
	author={Mocz, Philip},
	title={Vectorized N-body code (Python)},
	year={2020},
	url={https://github.com/pmocz/nbody-python},
}

@inproceedings{portham,
	title = "Port-Hamiltonian systems: an introductory survey",
	author = "{van der Schaft}, Arjan",
	year = "2006",
	language = "English",
	booktitle = "International Congress of Mathematicians, 2006",
	publisher = "European Mathematical Society Publishing House (EMS Ph)",
	
}

@misc{pybullet,
	author = {Erwin Coumans and Yunfei Bai},
	title = {PyBullet, a Python module for physics simulation for games, robotics and machine learning},
	howpublished = {\url{http://pybullet.org}},
	year = {2016--2019}
}
@article{dh,
	author = {Balasubramanian, Ravi},
	year = {2011},
	month = {01},
	pages = {},
	title = {The Denavit Hartenberg Convention}
}
@book{num,
	author = "Jens Lang",
	title = "Vorlesungskript Numerik Gewöhnlicher Differentialgleichungen",
	year = "2021",
	pages= "11-15" }
@book{SDRT2,
	author = "Jürgen Adamy",
	title = "Systemdynamik und Regelungstechnik II",
	year = "2010",
	publisher = "Shaker Verlag",
	pages= "135-144" }
@book{osci2,
	author="Garrett, Steven L.",
	title="The Simple Harmonic Oscillator",
	bookTitle="Understanding Acoustics: An Experimentalist's View of Sound and Vibration",
	year="2020",
	publisher="Springer International Publishing",
	address="Cham",
	pages="59--131",
	abstract="This chapter will introduce a system that is fundamental to our understanding of more physical phenomena than any other. Although the ``simple'' harmonic oscillator seems to be only the combination of the most mundane components, the formalism developed to explain the behavior of a mass, spring, and damper is used to describe systems that range in size from atoms to oceans. Our investigation goes beyond the ``traditional'' treatments found in the elementary physics textbooks. For example, the introduction of damping will open a two-way street: a damping element (i.e., a mechanical resistance, Rm) will dissipate the oscillator's energy, reducing the amplitudes of successive oscillations, but it will also connect the oscillator to the surrounding environment that will return thermal energy to the oscillator. The excitation of a harmonic oscillator by an externally applied force, displacement, or combination of the two will result in a response that is critically dependent upon the relationship between the frequency of excitation and the natural frequency of the oscillator and will introduce the critical concepts of mechanical impedance, resonance, and quality factor. Finally, the harmonic oscillator model will be extended to coupled oscillators that are represented by combinations of several masses and several springs.",
	isbn="978-3-030-44787-8",
	doi="10.1007/978-3-030-44787-8_2",
	url="https://doi.org/10.1007/978-3-030-44787-8_2"
}

@misc{jointspace,
	title={Joint Space Control via Deep Reinforcement Learning}, 
	author={Visak Kumar and David Hoeller and Balakumar Sundaralingam and Jonathan Tremblay and Stan Birchfield},
	year={2021},
	eprint={2011.06332},
	archivePrefix={arXiv},
	primaryClass={cs.RO},
	url={https://arxiv.org/abs/2011.06332}, 
}

@misc{delan,
	title={Deep Lagrangian Networks for end-to-end learning of energy-based control for under-actuated systems}, 
	author={Michael Lutter and Kim Listmann and Jan Peters},
	year={2019},
	eprint={1907.04489},
	archivePrefix={arXiv},
	primaryClass={cs.RO},
	url={https://arxiv.org/abs/1907.04489}, 
}
@article{holo,
	title={Operational classical mechanics: holonomic systems},
	volume={55},
	ISSN={1751-8121},
	url={http://dx.doi.org/10.1088/1751-8121/ac8f75},
	DOI={10.1088/1751-8121/ac8f75},
	number={40},
	journal={Journal of Physics A: Mathematical and Theoretical},
	publisher={IOP Publishing},
	author={Bermúdez Manjarres, A D},
	year={2022},
	month=sep, pages={405201} }

@article{iga,
	author = {Nguyen, Vinh Phu and Bordas, Stéphane and Rabczuk, Timon},
	year = {2012},
	month = {05},
	pages = {},
	title = {Isogeometric analysis: An overview and computer implementation aspects},
	volume = {117},
	journal = {Mathematics and Computers in Simulation},
	doi = {10.1016/j.matcom.2015.05.008}
}


@misc{fem,
	title={Eighty Years of the Finite Element Method: Birth, Evolution, and Future}, 
	author={Wing Kam Liu and Shaofan Li and Harold Park},
	year={2021},
	eprint={2107.04960},
	archivePrefix={arXiv},
	primaryClass={math.NA},
	url={https://arxiv.org/abs/2107.04960}, 
}
@incollection{pytorch,
	title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	
	booktitle = {Advances in Neural Information Processing Systems 32},
	pages = {8024--8035},
	year = {2019},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
} 


@inproceedings{autodiff,
	added-at = {2019-09-12T17:55:34.000+0200},
	author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	biburl = {https://www.bibsonomy.org/bibtex/2d9d4911f0310e65b1d54ff4c13f11aad/ross_mck},
	booktitle = {NIPS 2017 Workshop on Autodiff},
	interhash = {21530dd0202e55d3eb1ada151e09c499},
	intrahash = {d9d4911f0310e65b1d54ff4c13f11aad},
	keywords = {extraperi linbot2},
	location = {Long Beach, California, USA},
	timestamp = {2019-09-26T11:31:24.000+0200},
	title = {Automatic Differentiation in PyTorch},
	url = {https://openreview.net/forum?id=BJJsrmfCZ},
	year = 2017
}

@Article{Cuomo2022,
	author={Cuomo, Salvatore
	and Di Cola, Vincenzo Schiano
	and Giampaolo, Fabio
	and Rozza, Gianluigi
	and Raissi, Maziar
	and Piccialli, Francesco},
	title={Scientific Machine Learning Through Physics--Informed Neural Networks: Where we are and What's Next},
	journal={Journal of Scientific Computing},
	year={2022},
	month={Jul},
	day={26},
	volume={92},
	number={3},
	pages={88},
	abstract={Physics-Informed Neural Networks (PINN) are neural networks (NNs) that encode model equations, like Partial Differential Equations (PDE), as a component of the neural network itself. PINNs are nowadays used to solve PDEs, fractional equations, integral-differential equations, and stochastic PDEs. This novel methodology has arisen as a multi-task learning framework in which a NN must fit observed data while reducing a PDE residual. This article provides a comprehensive review of the literature on PINNs: while the primary goal of the study was to characterize these networks and their related advantages and disadvantages. The review also attempts to incorporate publications on a broader range of collocation-based physics informed neural networks, which stars form the vanilla PINN, as well as many other variants, such as physics-constrained neural networks (PCNN), variational hp-VPINN, and conservative PINN (CPINN). The study indicates that most research has focused on customizing the PINN through different activation functions, gradient optimization techniques, neural network structures, and loss function structures. Despite the wide range of applications for which PINNs have been used, by demonstrating their ability to be more feasible in some contexts than classical numerical techniques like Finite Element Method (FEM), advancements are still possible, most notably theoretical issues that remain unresolved.},
	issn={1573-7691},
	doi={10.1007/s10915-022-01939-z},
	url={https://doi.org/10.1007/s10915-022-01939-z}
}


@misc{neuralODE,
title={Neural Ordinary Differential Equations}, 
author={Ricky T. Q. Chen and Yulia Rubanova and Jesse Bettencourt and David Duvenaud},
year={2019},
eprint={1806.07366},
archivePrefix={arXiv},
primaryClass={cs.LG},
url={https://arxiv.org/abs/1806.07366}
}

@misc{Delan,
	title={Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning}, 
	author={Michael Lutter and Christian Ritter and Jan Peters},
	year={2019},
	eprint={1907.04490},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1907.04490}, 
}
@book{dalambert,
	title="CHAPTER IV. D'ALEMBERT'S PRINCIPLE. The Variational Principles of Mechanics",
	author= "Lanczos, Cornelius",
	publisher= "Toronto: University of Toronto Press",
	year = "1949",
	pages = "88-110",
	url= "https://doi.org/10.3138/9781487583057-007"}


@book{ClassPhy,
	author = { Matthew J. Benacquista , Joseph D. Romano},
	title = {Classical Mechanics },
	date = {2018},
	ISBN = {978-3-319-68779-7},


}
@inbook{osci, title={Harmonic Oscillator}, booktitle={Fundamentals of Mechanics}, publisher={Foundation Books}, author={Chandra, Suresh and Sharma, Mohit Kumar and Sharma, Monika}, year={2014}, pages={150–174}}

@inproceedings{dalam,
	title={Holonomic versus nonholonomic constraints},
	author={Mattias Flygare},
	year={2012},
	url={https://api.semanticscholar.org/CorpusID:118677177}
}
@misc{ortho,
	title={Virtual Displacement in Lagrangian Dynamics}, 
	author={Subhankar Ray and J. Shamanna},
	year={2004},
	eprint={physics/0410123},
	archivePrefix={arXiv},
	primaryClass={physics.ed-ph},
	url={https://arxiv.org/abs/physics/0410123}, 
}
@inproceedings{ham,
	author = "Montague, B. W.",
	title = "{Basic Hamiltonian mechanics}",
	booktitle = "{CERN Accelerator School: Course on Advanced Accelerator Physics (CAS)}",
	pages = "1--14",
	year = "1993"}


@inbook{mlprnn, place={Cambridge}, title={Foundations of Deep Learning}, booktitle={Deep Learning on Graphs}, publisher={Cambridge University Press}, author={Ma, Yao and Tang, Jiliang}, year={2021}, pages={43–72}} 
@article{acts,
	title={Activation functions in deep learning: A comprehensive survey and benchmark},
	author={Shiv Ram Dubey and Satish Kumar Singh and Bidyut Baran Chaudhuri},
	journal={Neurocomputing},
	year={2021},
	volume={503},
	pages={92-108},
	url={https://api.semanticscholar.org/CorpusID:250089226}
}

@misc{rnn,
	title={Recurrent Neural Networks (RNNs): A gentle Introduction and Overview}, 
	author={Robin M. Schmidt},
	year={2019},
	eprint={1912.05911},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1912.05911}, 
}
@Inbook{rnntypes,
	author="Das, Susmita
	and Tariq, Amara
	and Santos, Thiago
	and Kantareddy, Sai Sandeep
	and Banerjee, Imon",
	editor="Colliot, Olivier",
	title="Recurrent Neural Networks (RNNs): Architectures, Training Tricks, and Introduction to Influential Research",
	bookTitle="Machine Learning for Brain Disorders",
	year="2023",
	publisher="Springer US",
	address="New York, NY",
	pages="117--138",
	abstract="Recurrent neural networks (RNNs) are neural network architectures with hidden state and which use feedback loops to process a sequence of data that ultimately informs the final output. Therefore, RNN models can recognize sequential characteristics in the data and help to predict the next likely data point in the data sequence. Leveraging the power of sequential data processing, RNN use cases tend to be connected to either language models or time-series data analysis. However, multiple popular RNN architectures have been introduced in the field, starting from SimpleRNN and LSTM to deep RNN, and applied in different experimental settings. In this chapter, we will present six distinct RNN architectures and will highlight the pros and cons of each model. Afterward, we will discuss real-life tips and tricks for training the RNN models. Finally, we will present four popular language modeling applications of the RNN models --text classification, summarization, machine translation, and image-to-text translation-- thereby demonstrating influential research in the field.",
	isbn="978-1-0716-3195-9",
	doi="10.1007/978-1-0716-3195-9_4",
	url="https://doi.org/10.1007/978-1-0716-3195-9_4"
}
@article{gru,
	title={Gate-variants of Gated Recurrent Unit (GRU) neural networks},
	author={Rahul Dey and Fathi M. Salem},
	journal={2017 IEEE 60th International Midwest Symposium on Circuits and Systems (MWSCAS)},
	year={2017},
	pages={1597-1600},
	url={https://api.semanticscholar.org/CorpusID:8492900}
}
@misc{hnn,
	title={Hamiltonian Neural Networks}, 
	author={Sam Greydanus and Misko Dzamba and Jason Yosinski},
	year={2019},
	eprint={1906.01563},
	archivePrefix={arXiv},
	primaryClass={cs.NE},
	url={https://arxiv.org/abs/1906.01563}, 
}
@article{papthreebody,
	title={Three Classes of Newtonian Three-Body Planar Periodic Orbits},
	volume={110},
	ISSN={1079-7114},
	url={http://dx.doi.org/10.1103/PhysRevLett.110.114301},
	DOI={10.1103/physrevlett.110.114301},
	number={11},
	journal={Physical Review Letters},
	publisher={American Physical Society (APS)},
	author={Šuvakov, Milovan and Dmitrašinović, V.},
	year={2013},
	month=mar }

@online{web,
	author = {Institute of Physics Belgrade},
	title = {THREE-BODY GALLERY},
	url = {http://three-body.ipb.ac.rs/},
}
@article{hudomal2015new,
	title={New periodic solutions to the three-body problem and gravitational waves},
	author={Hudomal, Ana},
	journal={Master of Science Thesis at the Faculty of Physics, Belgrade University},
	year={2015}
}


@article{mlppic,
	title = {Deep neural networks in the cloud: Review, applications, challenges and research directions},
	journal = {Neurocomputing},
	volume = {545},
	pages = {126327},
	year = {2023},
	issn = {0925-2312},
	doi = {https://doi.org/10.1016/j.neucom.2023.126327},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231223004502},
	author = {Kit Yan Chan and Bilal Abu-Salih and Raneem Qaddoura and Ala’ M. Al-Zoubi and Vasile Palade and Duc-Son Pham and Javier Del Ser and Khan Muhammad},
	keywords = {Big data, Cloud computing, Deep neural networks, High-performance computing}
	
}

@inproceedings{rnn_picture,
	author = {Feng, Weijiang and Guan, Naiyang and Li, Yuan and Zhang, Xiang and Luo, Zhigang},
	year = {2017},
	month = {05},
	pages = {681-688},
	title = {Audio visual speech recognition with multimodal recurrent neural networks},
	doi = {10.1109/IJCNN.2017.7965918}
}

@article{gru_picture,
	author = {Mohsen, Saeed},
	year = {2023},
	month = {05},
	pages = {},
	title = {Recognition of human activity using GRU deep learning algorithm},
	volume = {82},
	journal = {Multimedia Tools and Applications},
	doi = {10.1007/s11042-023-15571-y}
}

@misc{adamW,
	title={Decoupled Weight Decay Regularization}, 
	author={Ilya Loshchilov and Frank Hutter},
	year={2019},
	eprint={1711.05101},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1711.05101}, 
}
@article{dopri5,
	title = {A fifth-order interpolant for the Dormand and Prince Runge-Kutta method},
	journal = {Journal of Computational and Applied Mathematics},
	volume = {29},
	number = {1},
	pages = {91-100},
	year = {1990},
	issn = {0377-0427},
	doi = {https://doi.org/10.1016/0377-0427(90)90198-9},
	url = {https://www.sciencedirect.com/science/article/pii/0377042790901989},
	author = {M. Calvo and J.I. Montijano and L. Randez},
	keywords = {Ordinary differential equations, Runge-Kutta methods, interpolation},
	abstract = {A family of fifth-order interpolants for the fifth-order solution provided by the Dormand and Prince Runge-Kutta pair RK5(4)7M which requires two additional function evaluations per step is presented. An optimal interpolant in this family has been determined by choosing the parameters to minimize the leading coefficients of the local truncation error of the continuous solution. Some numerical experiments with the nonstiff DETEST problems show that the proposed optimal method has a good interpolatory behavior.}
}

